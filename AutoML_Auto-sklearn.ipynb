{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab6e58f6-f7f3-40a7-a557-d89b9beb0b91",
   "metadata": {},
   "source": [
    "# Auto-sklearn approach\n",
    "## The following code can be used in an Jupyter Notebook (Python 3.8.X, Auto-sklearn 0.14.3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4913b1b-f584-4b71-b031-88d5a6a4bb64",
   "metadata": {},
   "source": [
    "__Import Python modules.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19375dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "import autosklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afd4e9-83ec-40c0-be31-9c542b1e0cc7",
   "metadata": {},
   "source": [
    "__Prepare the training data set.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1283400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'MetS Train.csv'\n",
    "df = read_csv(filename)\n",
    "array = df.values\n",
    "ID_train = array[:,0]\n",
    "X_train = array[:,1:-1]\n",
    "y_train = array[:,-1]\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = LabelEncoder().fit_transform(y_train.astype('str'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f76ef-40b8-4b85-abdd-c6e28beea080",
   "metadata": {},
   "source": [
    "__Build a Classification model__. A time budget of fifteen minutes has been set. The _n_jobs_ parameter establishes the number of jobs to run in parallel. The _per_run_time_limit_ value must be high enough so that a typical machine learning algorithm can be fit on the training data without exceeding this time limit. _Metric_ parameter represents the evaluation metric to evaluate the model performance. For classification, the possible values are: _roc_auc_, _precision_, _accuracy_, _balanced_accuracy_, _f1_, _f1_micro_, _f1_marco_, _f1_weighted_, _f1_samples_, _recall_, _recall_micro_, _recall_macro_, _recall_samples_, _recall_weighted_, _precision_macro_, _precision_micro_, _precision_samples_, _precision_weighted_, _log_loss_ and _average_percision_. \n",
    "_Fit_ both optimizes the machine learning models and builds an ensemble out of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b3576a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoSklearnClassifier(time_left_for_this_task=900, per_run_time_limit=300, n_jobs=2, metric=autosklearn.metrics.accuracy, ensemble_size=1, ensemble_class = 'SingleBest')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed1c61f",
   "metadata": {},
   "source": [
    "__Analysis and inspection of the model__. The _PipelineProfiler_ package is a very useful tool for interactive analysis and inspection of the classification model; the steps and algorithms used for its construction are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942f6a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import PipelineProfiler\n",
    "profiler_data = PipelineProfiler.import_autosklearn(model)\n",
    "PipelineProfiler.plot_pipeline_matrix(profiler_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9681fd",
   "metadata": {},
   "source": [
    "__Save optimized model to a file__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f96ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "filename = 'auto_model.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2a992b",
   "metadata": {},
   "source": [
    "__Restore tuned model from the file__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb3c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5c581",
   "metadata": {},
   "source": [
    "Prepare the testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e4d59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'MetS Test.csv'\n",
    "df = read_csv(filename)\n",
    "array = df.values\n",
    "ID_test = array[:,0]\n",
    "X_test = array[:,1:-1]\n",
    "y_test = array[:,-1]\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = LabelEncoder().fit_transform(y_test.astype('str'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee728740",
   "metadata": {},
   "source": [
    "__Score the machine learning model__: the predicted values and the probability estimates for each value are obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5532af6-fd1f-4247-aebd-ffe686e3485a",
   "metadata": {},
   "source": [
    "Predicting on test data using the tuned model. The _predict_proba_ function outputs predicted classes, as well as the probability estimates for each of the classes (confidence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd971a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "probs = loaded_model.predict_proba(X_test)\n",
    "pred_confidence = []\n",
    "for i in range(len(probs)):\n",
    "  if (y_pred[i]==0):\n",
    "    pred_confidence.append(probs[i, 0])\n",
    "  else:\n",
    "    pred_confidence.append(probs[i, 1]) \n",
    "\n",
    "ds_id = pd.DataFrame(ID_test, columns = [\"ID\"])\n",
    "ds_actual = pd.DataFrame(y_test, columns = [\"ACTUALVALUE\"])\n",
    "ds_pred = pd.DataFrame(y_pred, columns = [\"PREDICTEDVALUE\"])\n",
    "ds_prob = pd.DataFrame(pred_confidence, columns = [\"PREDICTIONCONFIDENCE\"])\n",
    "dataframe = pd.concat([ds_id, ds_actual, ds_pred, ds_prob], axis=1)\n",
    "dataframe.to_csv('autosklearn_test_pred.csv',index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24140e7",
   "metadata": {},
   "source": [
    "__Build the confusion matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739afaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab64f1",
   "metadata": {},
   "source": [
    "__Display the confusion matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31151df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "fig, ax = plot_confusion_matrix(conf_mat=conf_matrix, figsize=(2, 2), cmap=plt.cm.Greens)\n",
    "plt.xlabel('Predictions', fontsize=11)\n",
    "plt.ylabel('Actuals', fontsize=11)\n",
    "plt.title('Confusion Matrix', fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee06124",
   "metadata": {},
   "source": [
    "__Calculate the performance metrics__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "print('Precision: %.3f' % precision_score(y_test, y_pred))\n",
    "print('Recall: %.3f' % recall_score(y_test, y_pred))\n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))\n",
    "print('F1 Score: %.3f' % f1_score(y_test, y_pred))\n",
    "print('Specificity : %.3f' %recall_score(y_test, y_pred, pos_label=0))\n",
    "ba = (recall_score(y_test, y_pred, pos_label=0) + recall_score(y_test, y_pred))/2.0\n",
    "print('Balanced accuracy : %.3f' % ba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea907475-fa6a-470f-bcec-524436029827",
   "metadata": {},
   "source": [
    "__Prepares the test data for the calculation of SHAP values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15715ddb-7c2f-4d7e-bdd3-a7fa8ee1ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[['DMFT','CPI','Periodontal pockets','Bleeding','Tooth brushing','Dental control','Gingival attachment loss','CV risk','Carotid atherosclerosis','EQ-5D-5L score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595caff0-697f-4ba8-a533-513b49322c33",
   "metadata": {},
   "source": [
    "__A wrapper class for Auto-sklearn models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c973d-f8ab-475d-8a8f-f554aec734df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SKLProbWrapper:\n",
    "    def __init__(self, skl_model, feature_names):\n",
    "        self.skl_model = skl_model\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    def predict_binary_prob(self, X):\n",
    "        if isinstance(X, pd.Series):\n",
    "            X = X.values.reshape(1,-1)\n",
    "        self.dataframe= pd.DataFrame(X, columns=self.feature_names)\n",
    "        self.predictions = self.skl_model.predict_proba(self.dataframe.values)\n",
    "        return self.predictions.astype('float64')[:,-1] #probability of True class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9eb8cd-6a5e-4dcc-9c5a-122634fd7315",
   "metadata": {},
   "source": [
    "__SHAP explainer instantiation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8fb2c-a422-4737-a0ae-9a24edf54f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_wrapper = SKLProbWrapper(model, df_train.columns)\n",
    "skl_explainer = shap.KernelExplainer(skl_wrapper.predict_binary_prob, df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca815656-07ea-4685-80e4-8ee0646d14c3",
   "metadata": {},
   "source": [
    "__Computing SHAP values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb46cc4-2b9b-4558-be2e-0188e043244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = skl_explainer(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6716eb8d-a06e-4b00-b0c0-9c2b437005f2",
   "metadata": {},
   "source": [
    "__Show summary plot__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb3344-5d99-4a95-824c-fb793c39df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values.values, df_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
